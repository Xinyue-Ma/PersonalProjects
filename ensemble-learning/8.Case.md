# Case 2
Ensemble内的各个模型不仅仅可以是同一个模型根据训练集合的随机子集进行训练（得到不同的参数），也可以不同的模型进行组合、甚至可以是针对不同的特征子集进行训练。之后各个模型可以通过不同的策略进行组合。但是不同的结果输出，组合的情况是不同的，这里主要包括三种情况:

1)Abstract-level:各个模型只输出一个目标类别，如猫、狗和人的图像识别中，仅输出人；
2)Rank-level:各个模型是输出目标类别的一个排序，如猫、狗和人的图像识别中，输出人-狗-猫；
3)measurement-level:各个模型输出的是目标类别的概率估计或一些相关的信念值，如猫、狗和人的图像识别中，输出0.7人-0.2狗-0.1猫；
可以用数学表示为，对于输出是Abstract-level的，第t个模型定义可以为 dt,j∈0,1,t=1,...,T;j=1,...,C, 这里T表示模型个数，C表示类别数。如果第t个模型选择了类别wj, 那么dt,j=1。如果输出是连续值, dt,j∈[0,1]，我们总是可以归一化，使得每个值表示各个类别的后验概率估计Pt(wj｜x).

Algebraic combiners(代数组合器)是非训练得到的组合器，这里通常用于有数值输出的情况。一般使用最小值、最大值、求和、均值、求积、中位数等等，进行最终的决策。也要Voting based methods（基于投票），一般用于离散的情况，比较常见的是按众数决策。也要按照 Weighted majority voting，即各个模型的结果有不同的权重，加权得到最终的结果，这里的权重可以通过学习得到。

当然，也可以使用其他的组合方法，比如上面提到的使用perceptron或logistic做组合器。但是，经验上来说，使用简单的组合规则比如求和或者众数投票，都可以达到非常好的结果.
